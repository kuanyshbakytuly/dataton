{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kuanyshbakytuly/dataton/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCHnWyJk0Q5G"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms,models,datasets\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from torch import optim\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu' #turn on gpu manually on google.colab\n",
        "import cv2, glob, numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from glob import glob\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0BOBLZp5duS"
      },
      "outputs": [],
      "source": [
        "#Collecting labels from \"train_labels.csv\" and saving them in upd_dictionary\n",
        "\n",
        "df = pd.read_csv(\"/train_labels.csv\")\n",
        "df.rename(columns = {'2418.jpg': 'image'}, inplace = True)\n",
        "df.rename(columns = {'1': 'Y'}, inplace = True)\n",
        "dicts = df.to_dict(orient=\"index\")\n",
        "\n",
        "upd_dict = {}\n",
        "for k, v in dicts.items():\n",
        "  for k1, v1 in v.items():\n",
        "    if len(k1) == 1:\n",
        "      upd_dict[keys] = v1\n",
        "    else:\n",
        "      keys = v1\n",
        "\n",
        "upd_dict[\"2418.jpg\"] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56HMIL8K0poZ"
      },
      "outputs": [],
      "source": [
        "#folders\n",
        "train_data = \"/content/train_imgs\"\n",
        "valid_data = \"/content/train_imgs\"\n",
        "test_data =\"/content/test_imgs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dR2RSeYk1Of6"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "class Data(Dataset):\n",
        "    #Providing the class that returns images and targets from folder\n",
        "\n",
        "    def __init__(self, folder, lower_bound=0, upper_bound=-1):\n",
        "        #Initializing from folder with lower_bound and upper_bound\n",
        "        images_in_folder =  glob(folder + '/*.jpg')\n",
        "        self.images = images_in_folder[lower_bound: upper_bound] \n",
        "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
        "        self.targets = [upd_dict[image_path.split('/')[-1]] for image_path in self.images]\n",
        "\n",
        "    def __len__(self): \n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        #Getting images[i] and its target\n",
        "        image_path = self.images[i]\n",
        "        target = self.targets[i]\n",
        "\n",
        "        im = (cv2.imread(image_path)[:,:,::-1])\n",
        "        im = self.image_segmentation(im)\n",
        "        im = cv2.resize(im, (224,224))\n",
        "        im = torch.tensor(im/255)\n",
        "        im = im.permute(2,0,1)\n",
        "        im = self.normalize(im) \n",
        "\n",
        "        return im.float().to(device), torch.tensor([target]).float().to(device)\n",
        "\n",
        "    def image_segmentation(self, image):\n",
        "        #Returning edited images with fire segmentation\n",
        "        image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "        lower_hsv = np.array([0,0,250]) #orange\n",
        "        upper_hsv = np.array([250,255,255]) #black\n",
        "    \n",
        "        mask = cv2.inRange(image_hsv, lower_hsv, upper_hsv)\n",
        "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\n",
        "        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "        output = cv2.bitwise_and(image, image, mask = mask) / 255\n",
        "        image_blurred = cv2.GaussianBlur(image, (0, 0), 3)\n",
        "        image_sharp = cv2.addWeighted(image, 1.5, image_blurred, -0.5, 0)\n",
        "        return image_sharp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXyRQg4y2Kb4"
      },
      "outputs": [],
      "source": [
        "def get_model():\n",
        "    model = models.vgg16(pretrained=True)\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    model.avgpool = nn.AdaptiveAvgPool2d(output_size=(1,1))\n",
        "    model.classifier = nn.Sequential(nn.Flatten(),\n",
        "    nn.Linear(512, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.2),\n",
        "    nn.Linear(128, 1),\n",
        "    nn.Sigmoid())\n",
        "\n",
        "    #loss_function - Binary Cross Entropy\n",
        "    #optimizer - Adam\n",
        "    #Recommended by https://www.mdpi.com/1424-8220/22/5/1701 for Fire Classifying\n",
        "    loss_fn = nn.BCELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr= 1e-3)\n",
        "    return model.to(device), loss_fn, optimizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data():\n",
        "    #Returning training and validation DataLoader \n",
        "    lower = 0\n",
        "    upper = 2500\n",
        "    train = Data(train_data, lower, upper)\n",
        "    trn_dl = DataLoader(train, batch_size=32, shuffle=True, drop_last = True)\n",
        "    val = Data(valid_data, upper, upper+200)\n",
        "    val_dl = DataLoader(val, batch_size=32, shuffle=True, drop_last = True)\n",
        "    return trn_dl, val_dl"
      ],
      "metadata": {
        "id": "K2wNQoIsaJ7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqzB9Zqm27WG"
      },
      "outputs": [],
      "source": [
        "def train_batch(x, y, model, opt, loss_fn):\n",
        "    #Returns loss variables, optimizing after each step\n",
        "    optimizer.zero_grad()\n",
        "    prediction = model(x)\n",
        "    batch_loss = loss_fn(prediction, y)\n",
        "    batch_loss.backward()\n",
        "    optimizer.step()\n",
        "    return batch_loss.item()\n",
        "\n",
        "@torch.no_grad()\n",
        "def accuracy(x, y, model):\n",
        "    #Evaluating the model without training it\n",
        "    prediction = model(x)\n",
        "\n",
        "    #if 0<prediction<0.5 => return False\n",
        "    #else True\n",
        "    is_correct = (prediction > 0.5) == y\n",
        "    return is_correct.cpu().numpy().tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8WqYJcn3Mrc"
      },
      "outputs": [],
      "source": [
        "trn_dl, val_dl = get_data()\n",
        "model, loss_fn, optimizer = get_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JciaKglx3SAV"
      },
      "outputs": [],
      "source": [
        "train_losses, train_accuracies = [], []\n",
        "val_accuracies = []\n",
        "epoches = 10\n",
        "for epoch in epoches:\n",
        "    #Training the model over increasing epochs\n",
        "    print(f\" epoch {epoch + 1}/{epoches}\")\n",
        "    train_epoch_losses, train_epoch_accuracies = [], []\n",
        "    val_epoch_accuracies = []\n",
        "\n",
        "    for ix, batch in enumerate(iter(trn_dl)):\n",
        "        x, y = batch\n",
        "        batch_loss = train_batch(x, y, model, optimizer, loss_fn)\n",
        "        train_epoch_losses.append(batch_loss) \n",
        "    train_epoch_loss = np.array(train_epoch_losses).mean()\n",
        "\n",
        "    for ix, batch in enumerate(iter(trn_dl)):\n",
        "        x, y = batch\n",
        "        is_correct = accuracy(x, y, model)\n",
        "        train_epoch_accuracies.extend(is_correct)\n",
        "    train_epoch_accuracy = np.mean(train_epoch_accuracies)\n",
        "\n",
        "    for ix, batch in enumerate(iter(val_dl)):\n",
        "        x, y = batch\n",
        "        val_is_correct = accuracy(x, y, model)\n",
        "        val_epoch_accuracies.extend(val_is_correct)\n",
        "    val_epoch_accuracy = np.mean(val_epoch_accuracies)\n",
        "\n",
        "    train_losses.append(train_epoch_loss)\n",
        "    train_accuracies.append(train_epoch_accuracy)\n",
        "    val_accuracies.append(val_epoch_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlTBkr0z8rqc"
      },
      "outputs": [],
      "source": [
        "epochs = np.arange(epoches)+1\n",
        "import matplotlib.ticker as mtick\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as mticker\n",
        "%matplotlib inline\n",
        "plt.plot(epochs, train_accuracies, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_accuracies, 'r', label='Validation accuracy')\n",
        "plt.gca().xaxis.set_major_locator(mticker.MultipleLocator(1))\n",
        "plt.title('Training and validation accuracy with ResNET34 \\nand 2500 training data points')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim(0.9,1)\n",
        "plt.gca().set_yticklabels(['{:.0f}%'.format(x*100) for x in plt.gca().get_yticks()]) \n",
        "plt.legend()\n",
        "plt.grid('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model.pth')"
      ],
      "metadata": {
        "id": "W1RlDVvcnW3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6e5c_m5C1Ys"
      },
      "outputs": [],
      "source": [
        "model, x, y = get_model()\n",
        "model.load_state_dict(torch.load('/content/resnet34.pth'))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Test(Dataset):\n",
        "    #Providing the class that returns images\n",
        "\n",
        "    def __init__(self, folder):\n",
        "        #Initializing images from folder \n",
        "        images_in_folder =  glob(folder + '/*.jpg')\n",
        "        self.images = [image_path for image_path in images_in_folder]\n",
        "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
        "\n",
        "    def __len__(self): \n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        #Getting images[i] and its target\n",
        "        image_path = self.images[i]\n",
        "        im = (cv2.imread(image_path)[:,:,::-1])\n",
        "        im = cv2.resize(im, (224,224))\n",
        "        im = torch.tensor(im/255)\n",
        "        im = im.permute(2,0,1)\n",
        "        im = self.normalize(im) \n",
        "\n",
        "        return im.float().to(device),  image_path.split(\"/\")[-1] "
      ],
      "metadata": {
        "id": "CvmukBsHDra6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def accuracy_testing(x, model):\n",
        "    #Evaluating the model without training it\n",
        "    prediction = model(x)\n",
        "\n",
        "    #if 0<prediction<0.5 => return False\n",
        "    #else True\n",
        "    is_correct = (prediction > 0.5)\n",
        "    return is_correct.cpu().numpy().tolist()"
      ],
      "metadata": {
        "id": "EilsGs-KFWc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = Test(test_data)\n",
        "tst_dl = DataLoader(test, batch_size=1, shuffle=True, drop_last = True)"
      ],
      "metadata": {
        "id": "3uEnEbGfESXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vI845UuqC1xX"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "dict_test = {}\n",
        "for ix, batch in enumerate(iter(tst_dl)):\n",
        "    x, image_name = batch\n",
        "    test_is_correct = accuracy_testing(x, model)\n",
        "    dict_test[image_name[0]] = int(test_is_correct[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(pd.DataFrame.from_dict(data=dict_test, orient='index')\n",
        "   .to_csv('/content/answer.csv', header=False))"
      ],
      "metadata": {
        "id": "82yWQMoi4Cj9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1vhxvWcfW-qM5DiYNadxexVNyUnCBRCxR",
      "authorship_tag": "ABX9TyNyuCuyZUaAn8Sa78hxszP2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}