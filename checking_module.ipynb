{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1DADiGQkZ9q8_bip554Fdt4WHQjiYQ7AP",
      "authorship_tag": "ABX9TyMxktf5M9zWUnxEFJiQynTa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kuanyshbakytuly/dataton/blob/main/checking_module.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "dmjwoZw7GnsD"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms,models,datasets\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from torch import optim\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "import cv2, glob, numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from glob import glob\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = \"/content/test_imgs\""
      ],
      "metadata": {
        "id": "d3jlwQmFGwvk"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model():\n",
        "    #Returning the pretrained model - ResNET34\n",
        "    model = models.resnet34(pretrained=True)\n",
        "\n",
        "    #Freezing all parameters\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    model.avgpool = nn.AdaptiveAvgPool2d(output_size=(1,1))\n",
        "    model.fc = nn.Sequential(nn.Flatten(),\n",
        "    nn.Linear(512, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.2),\n",
        "    nn.Linear(128, 1),\n",
        "    nn.Sigmoid())\n",
        "\n",
        "    #loss_function - Binary Cross Entropy\n",
        "    #optimizer - Adam\n",
        "    #Recommended by https://www.mdpi.com/1424-8220/22/5/1701 for Fire Classifying\n",
        "    loss_fn = nn.BCELoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr= 1e-3)\n",
        "    return model.to(device), loss_fn, optimizer"
      ],
      "metadata": {
        "id": "e28YrAWgGydc"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def accuracy_testing(x, model):\n",
        "    #Evaluating the model without training it\n",
        "    prediction = model(x)\n",
        "\n",
        "    #if 0<prediction<0.5 => return False\n",
        "    #else True\n",
        "    is_correct = (prediction > 0.5)\n",
        "    return is_correct.cpu().numpy().tolist()"
      ],
      "metadata": {
        "id": "9pq9r9opRJYs"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, x, y = get_model()\n",
        "model.load_state_dict(torch.load('/content/resnet34.pth'))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "L0ZwRxWsG10T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "class Test(Dataset):\n",
        "    #Providing the class that returns images\n",
        "\n",
        "    def __init__(self, folder):\n",
        "        #Initializing images from folder \n",
        "        images_in_folder =  glob(folder + '/*.jpg')\n",
        "        self.images = [image_path for image_path in images_in_folder]\n",
        "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
        "\n",
        "    def __len__(self): \n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        #Getting images[i] and its target\n",
        "        image_path = self.images[i]\n",
        "        im = (cv2.imread(image_path)[:,:,::-1])\n",
        "        im = cv2.resize(im, (224,224))\n",
        "        im = torch.tensor(im/255)\n",
        "        im = im.permute(2,0,1)\n",
        "        im = self.normalize(im) \n",
        "\n",
        "        return im.float().to(device),  image_path.split(\"/\")[-1] "
      ],
      "metadata": {
        "id": "F1IC8gdzRH-E"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = Test(test_data)\n",
        "tst_dl = DataLoader(test, batch_size=1, shuffle=True, drop_last = True)"
      ],
      "metadata": {
        "id": "ac6cSihCHtRz"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "dict_test = {}\n",
        "for ix, batch in enumerate(iter(tst_dl)):\n",
        "    x, image_name = batch\n",
        "    test_is_correct = accuracy_testing(x, model)\n",
        "    dict_test[image_name[0]] = int(test_is_correct[0][0])"
      ],
      "metadata": {
        "id": "9sD1qXEuHuTc"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(pd.DataFrame.from_dict(data=dict_test, orient='index')\n",
        "   .to_csv('/content/answer.csv', header=False))"
      ],
      "metadata": {
        "id": "bLrwFkJcHwQK"
      },
      "execution_count": 25,
      "outputs": []
    }
  ]
}